{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Construct Custum Dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "hiUzaztDMbXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pydicom numpy matplotlib Pillow\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pydicom\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, utils\n",
        "import random"
      ],
      "metadata": {
        "id": "XRpr8eQSRAXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1808d971-5186-4e7f-9f46-4435fc7f17d2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_image(image):\n",
        "    \"\"\"\n",
        "    Normalize image to the range [0, 1].\n",
        "    \"\"\"\n",
        "    image = image - np.min(image)\n",
        "    return image / np.max(image)\n",
        "\n",
        "def GrayScaleToBlueToRedColor(intensity, norm_value):\n",
        "    \"\"\"\n",
        "    intensity: pixel intensity value\n",
        "    norm_value: max value (e.g. 2^8-1)\n",
        "    \"\"\"\n",
        "    value = 4.0 * (float(intensity) / float(norm_value)) + 1\n",
        "\n",
        "    return (\n",
        "        norm_value * np.max([0.0, (3.0 - abs(value - 4) - abs(value - 5)) / 2]),\n",
        "        norm_value * np.max([0.0, (4.0 - abs(value - 2) - abs(value - 4)) / 2]),\n",
        "        norm_value * np.max([0.0, (3.0 - abs(value - 1) - abs(value - 2)) / 2]),\n",
        "    )\n",
        "\n",
        "def GrayImageToColorImage(image):\n",
        "    \"\"\"\n",
        "    image:grayscale image\n",
        "    \"\"\"\n",
        "    image = normalize_image(image)\n",
        "    colored_image = np.zeros([image.shape[0], image.shape[1], 3], dtype=np.uint8)\n",
        "    Imax = np.max(image.ravel())\n",
        "\n",
        "    for i in range(0, image.shape[0]):\n",
        "        for j in range(0, image.shape[1]):\n",
        "            sRGB = GrayScaleToBlueToRedColor(image[i, j], Imax)\n",
        "            colored_image[i, j, 2] = np.floor(sRGB[0]).astype(int)\n",
        "            colored_image[i, j, 1] = np.floor(sRGB[1]).astype(int)\n",
        "            colored_image[i, j, 0] = np.floor(sRGB[2]).astype(int)\n",
        "\n",
        "    return colored_image"
      ],
      "metadata": {
        "id": "8ETW4ZOcWQjf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of patient's age is: 33Y, so we need to convert to int\n",
        "def string2age(dcm):\n",
        "  age_list = list(dcm.PatientAge)\n",
        "  age_list = ''.join(age_list[:-1])\n",
        "  return int(age_list)\n",
        "\n",
        "def create_age_mark(based_dir):\n",
        "  age_mark = []\n",
        "  for patient_file in os.listdir(based_dir):\n",
        "    patient_dir = os.path.join(based_dir, patient_file)\n",
        "    dcm_path = os.path.join(patient_dir, os.listdir(patient_dir)[0])\n",
        "    dcm = pydicom.read_file(dcm_path, force= True)\n",
        "    age_mark.append(string2age(dcm))\n",
        "  return age_mark\n",
        "\n",
        "def create_3D_slice(patient_dir):\n",
        "  patient_slice = []\n",
        "\n",
        "  index_list = random.sample(range(len(os.listdir(patient_dir))),30)\n",
        "\n",
        "  for index in index_list:\n",
        "    dcm_file = os.listdir(patient_dir)[index]\n",
        "    dcm_path = os.path.join(patient_dir, dcm_file)\n",
        "    dcm = pydicom.read_file(dcm_path, force= True)\n",
        "    patient_slice.append(dcm)\n",
        "\n",
        "  patient_slice = sorted(patient_slice, key=lambda s: s.SliceLocation)  # sort slices by location\n",
        "\n",
        "  img_shape = [224,224,3]\n",
        "  #img_shape.append(3)\n",
        "  img_shape.append(len(patient_slice))\n",
        "  slice_3d = np.zeros(img_shape)\n",
        "\n",
        "  for i in range(len(patient_slice)):       ## Sample slices with step=3\n",
        "      gray_image = Image.fromarray(patient_slice[i].pixel_array)\n",
        "      if gray_image.mode == 'I;16':\n",
        "        gray_image = gray_image.convert('I')\n",
        "      resize_image = transforms.Resize((224,224))(gray_image)\n",
        "      resize_image_array = np.array(resize_image)\n",
        "      slice_3d[:,:,:,i] = GrayImageToColorImage(resize_image_array)  ## Resize to (224,224) first\n",
        "\n",
        "  return slice_3d"
      ],
      "metadata": {
        "id": "bMKGWFL-bqhq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LwJgGFy2MZpH"
      },
      "outputs": [],
      "source": [
        "from types import NoneType\n",
        "# to store whole dataset\n",
        "class PatientDataset(Dataset):\n",
        "  def __init__(self, based_dir, transform=None):\n",
        "    self.based_dir = based_dir\n",
        "    self.transform = transform\n",
        "    self.ageMark = create_age_mark(based_dir)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.ageMark)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    dir_list = os.listdir(self.based_dir)\n",
        "    patient_dir = os.path.join(self.based_dir, dir_list[index])\n",
        "    patient_slice = create_3D_slice(patient_dir)\n",
        "    agemark = self.ageMark[index]\n",
        "    sample = {'patient': torch.tensor(patient_slice), 'agemark': agemark}\n",
        "    if self.transform:\n",
        "      sample['patient'] = self.transform(sample['patient'])\n",
        "      sample['agemark'] = self.transform(sample['agemark'])\n",
        "    return sample"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_transform = transforms.Compose([transforms.ToPILImage(),\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor()])\n",
        "\n",
        "patient_dataset = PatientDataset(based_dir=\"/content/drive/MyDrive/Experiment_Dataset/\")\n",
        "for i, sample in enumerate(patient_dataset):\n",
        "    print(i, sample['patient'].shape, sample['agemark'])\n",
        "\n",
        "train_set, valid_set = random_split(patient_dataset, [0.8, 0.2])\n",
        "train_dataloader = DataLoader(train_set, batch_size=2, shuffle=True)\n",
        "print(f\"Training set size: {len(train_set)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Wtdw8ugBl2i",
        "outputId": "c06fdd73-a6d7-470f-f986-911ad9cff6c6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 torch.Size([224, 224, 3, 30]) 78\n",
            "1 torch.Size([224, 224, 3, 30]) 67\n",
            "2 torch.Size([224, 224, 3, 30]) 39\n",
            "3 torch.Size([224, 224, 3, 30]) 51\n",
            "4 torch.Size([224, 224, 3, 30]) 31\n",
            "5 torch.Size([224, 224, 3, 30]) 67\n",
            "6 torch.Size([224, 224, 3, 30]) 28\n",
            "7 torch.Size([224, 224, 3, 30]) 27\n",
            "8 torch.Size([224, 224, 3, 30]) 32\n",
            "9 torch.Size([224, 224, 3, 30]) 51\n",
            "10 torch.Size([224, 224, 3, 30]) 41\n",
            "11 torch.Size([224, 224, 3, 30]) 20\n",
            "Training set size: 10\n"
          ]
        }
      ]
    }
  ]
}